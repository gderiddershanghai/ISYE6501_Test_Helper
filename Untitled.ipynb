{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43365ff8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error: OpenAI version 0.27.5 is less than the required version 1.1.1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m current_version \u001b[38;5;241m=\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(openai\u001b[38;5;241m.\u001b[39m__version__)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m current_version \u001b[38;5;241m<\u001b[39m required_version:\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: OpenAI version \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mopenai\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is less than the required version 1.1.1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenAI version is compatible.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Error: OpenAI version 0.27.5 is less than the required version 1.1.1"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from packaging import version\n",
    "\n",
    "required_version = version.parse(\"1.1.1\")\n",
    "current_version = version.parse(openai.__version__)\n",
    "\n",
    "if current_version < required_version:\n",
    "    raise ValueError(f\"Error: OpenAI version {openai.__version__}\"\n",
    "                     \" is less than the required version 1.1.1\")\n",
    "else:\n",
    "    print(\"OpenAI version is compatible.\")\n",
    "\n",
    "# -- Now we can get to it\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=\"sk-xxx\")  # should use env variable OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad2e0b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty text files created successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the folder where you want to create the files\n",
    "folder_path = \"/home/ginger/code/gderiddershanghai/ISYE6501_Test_Helper/data\"\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "# Create empty text files numbered from 1 to 16\n",
    "for i in range(1, 17):\n",
    "    file_name = f\"Module_{i}.txt\"\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "    # Create an empty text file\n",
    "    with open(file_path, \"w\") as file:\n",
    "        pass  # This creates an empty file\n",
    "\n",
    "print(\"Empty text files created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed0b639b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aeed5a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(0,15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f3422dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    For each of the models (a-m) below, circle one type of question (i-viii) it is commonly used for.\n",
      "    For models that have more than one correct answer, choose any one correct answer;\n",
      "    for models that have no correct answer listed, do not circle anything.\n",
      "\n",
      "    Models:\n",
      "        a. ARIMA\n",
      "        b. CART\n",
      "        c. Cross validation\n",
      "        d. CUSUM\n",
      "        e. Exponential smoothing\n",
      "        f. GARCH\n",
      "        g. k-means\n",
      "        h. k-nearest-neighbor\n",
      "        i. Linear regression\n",
      "        j. Logistic regression\n",
      "        k. Principal component analysis\n",
      "        l. Random forest\n",
      "        m. Support vector machine\n",
      "\n",
      "    Question Types:\n",
      "        i. Change detection\n",
      "        ii. Classification\n",
      "        iii. Clustering\n",
      "        iv. Feature-based prediction of a probability\n",
      "        v. Feature-based prediction of a value\n",
      "        vi. Time-series-based prediction\n",
      "        vii. Validation\n",
      "        viii. Variance estimation\n",
      "\n",
      "    Returns:\n",
      "        A dictionary mapping each model to its associated question type.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from module.general_questions_m1 import MIDTERM_1_QUESTIONS\n",
    "print(MIDTERM_1_QUESTIONS[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47e0a0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.exam_tester import exam_prep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "473db395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from questions.general_questions_m1 import MIDTERM_1_QUESTIONS\n",
    "from questions.general_questions_m2 import MIDTERM_2_QUESTIONS\n",
    "from questions.knowledge_check_m1 import KNOWLEDGE_1_QUESTIONS\n",
    "from questions.knowledge_check_m2 import KNOWLEDGE_2_QUESTIONS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4377dcdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n    This function maps various statistical and machine learning models to commonly used question types.\\n\\n    For each of the models (a-m) below, circle one type of question (i-viii) it is commonly used for.\\n    For models that have more than one correct answer, choose any one correct answer;\\n    for models that have no correct answer listed, do not circle anything.\\n\\n    Models:\\n        a. ARIMA\\n        b. CART\\n        c. Cross validation\\n        d. CUSUM\\n        e. Exponential smoothing\\n        f. GARCH\\n        g. k-means\\n        h. k-nearest-neighbor\\n        i. Linear regression\\n        j. Logistic regression\\n        k. Principal component analysis\\n        l. Random forest\\n        m. Support vector machine\\n\\n    Question Types:\\n        i. Change detection\\n        ii. Classification\\n        iii. Clustering\\n        iv. Feature-based prediction of a probability\\n        v. Feature-based prediction of a value\\n        vi. Time-series-based prediction\\n        vii. Validation\\n        viii. Variance estimation\\n\\n    Returns:\\n        A dictionary mapping each model to its associated question type.\\n    ',\n",
       " '\\nSelect all of the following models that are designed for use with attribute/feature data (i.e., not time-series data):\\n\\n- CUSUM\\n- Logistic regression\\n- Support vector machine\\n- GARCH\\n- Random forest\\n- k-means\\n- Linear regression\\n- k-nearest-neighbor\\n- ARIMA\\n- Principal component analysis\\n- Exponential smoothing\\n',\n",
       " '\\nQuestion 1\\nIn the soft classification SVM model where we select coefficients to minimize the following formula:\\nΣ_{j=1}^n max{0, 1 - (Σ_{i=1}^m a_ix_ij + a_0)y_j} + C Σ_{i=1}^m a_i^2\\nSelect all of the following statements that are correct.\\n\\n- Decreasing the value of C could decrease the margin.\\n- Allowing a larger margin could decrease the number of classification errors in the training set.\\n- Decreasing the value of C could increase the number of classification errors in the training set.\\n\\nYou have used 1 of 1 attempt. Some problems have options such as save, reset, hints, or show answer. These options follow the Submit button.\\n\\nQuestion 2\\nIn the hard classification SVM model, it might be desirable to not put the classifier in a location that has equal margin on both sides... (select all correct answers):\\n\\n- ...because moving the classifier will usually result in fewer classification errors in the validation data.\\n- ...because moving the classifier will usually result in fewer classification errors in the test data.\\n- ...when the costs of misclassifying the two types of points are significantly different.\\n',\n",
       " '\\nThe table below shows the Akaike Information Criterion (AIC), Corrected AIC, and Bayesian Information Criterion (BIC) for each of the models.\\n\\nModel       AIC     Corrected AIC    BIC\\n1           -5.58   -5.32            2.07\\n2           -5.67   -5.15            3.89\\n3           -6.51   -5.62            4.96\\n4           -4.77   -3.41            8.61\\n5           -2.80   -0.85            12.49\\n6           -1.31   1.35             15.90\\n7           0.19    3.71             19.31\\n\\nQuestion 4c\\n0.75/3.0 points (graded)\\nBased on the table above and the figure shown for Question 4a, select all of the following statements that are correct.\\n\\n- Adjusted [metric from figure above 4a] and BIC (see table above 4c) give qualitatively opposite evaluations of Model 1.\\n- Among Models 1 and 3, AIC suggests that Model 1 is e^(-6.51-(5.58))/2 = 62.8 percent as likely as Model 3 to be better.\\n- Among Models 1 and 3, AIC suggests that Model 3 is e^(-6.51-(5.58))/2 = 62.8 percent as likely as Model 1 to be better.\\n- BIC suggests that Model 3 is very likely to be better than Model 4.\\n',\n",
       " \"\\n    An airline wants to predict airline passenger traffic for the upcoming year.\\n    For each of the specific questions (a-e) listed below, identify the question type (i-viii) it corresponds to.\\n    If a question does not match any of the listed types, leave it uncircled.\\n\\n    Question Types:\\n        i. Change detection\\n        ii. Classification\\n        iii. Clustering\\n        iv. Feature-based prediction of a value\\n        v. Feature-based prediction of a probability\\n        vi. Time-series-based prediction\\n        vii. Validation\\n        viii. Variance estimation\\n\\n    Questions:\\n        a. What is the probability that the airline will exceed 1 million passengers next year, considering current travel trends and economic factors?\\n        b. Among various forecasting models for airline passenger traffic, which one is likely to be the most accurate for the upcoming year?\\n        c. Based on the past decade's data, how many passengers are expected to travel via the airline next year?\\n        d. Analyzing the past fifteen years of data, has there been a significant change in passenger traffic during holiday seasons?\\n        e. Considering economic indicators and travel trends over the past 25 years, which years had the most similar passenger traffic patterns?\\n    \",\n",
       " \"\\nInformation for all parts of Question 5\\nAtlanta’s main library has collected the following day-by-day data over the past six years (more than 2000 data points):\\n\\nx1 = Number of books borrowed from the library on that day\\nx2 = Day of the week\\nx3 = Temperature\\nx4 = Amount of rainfall\\nx5 = Whether the library was closed that day\\nx6 = Whether public schools were open that day\\nx7 = Number of books borrowed the day before\\nt = Time\\n\\nQuestion 5a\\n\\nSelect all data that are categorical (including binary data):\\n\\n- Number of books borrowed from the library on that day\\n- Day of the week (correct)\\n- Temperature\\n- Amount of rainfall\\n- Whether the library was closed that day (correct)\\n- Whether public schools were open that day\\n\\nQuestions 5b and 5c\\n\\nThe library believes that there is a day-by-day word-of-mouth marketing effect: if more books were borrowed yesterday, then more books will be borrowed today (and if fewer books were borrowed yesterday, fewer books will be borrowed today), so they add a new predictor:\\n\\nx7 = number of books borrowed the day before\\n\\nb. If the library is correct that on average, if more books were borrowed yesterday, more books will be borrowed today (and vice versa), what sign (positive or negative) would you expect the new predictor's coefficient β to have?\\n\\n- Negative, because higher values of x7 decrease the response (books borrowed today)\\n- Negative, because on average the number of books borrowed each day is decreasing\\n- Positive, higher values of x7 increase the response (books borrowed today) (correct)\\n\\nc. Does x7 make the model autoregressive?\\n\\n- Yes, because the model does not use any day t data to predict day t+1 borrowing.\\n- Yes, because the model uses day t-1 borrowing data to predict day t borrowing. (correct)\\n- No, because the model does not use previous response data to predict the day t response.\\n\",\n",
       " '\\nSelect all of the following statements that are correct:\\n\\n- It is likely that the first principal component has much more predictive power than each of the other principal components.\\n- It is likely that the first original covariate has much more predictive power than each of the other covariates.\\n- It is likely that the last original covariate has much less predictive power than each of the other covariates.\\n- The first principal component cannot contain information from all 7 original covariates. (correct)\\n',\n",
       " '\\nRecall the equations for triple exponential smoothing (Winters’/Holt-Winters method):\\nS_t = α * (x_t / C_(t-L)) + (1 - α) * (S_(t-1) + T_(t-1))\\nT_t = β * (S_t - S_(t-1)) + (1 - β) * T_(t-1)\\nC_t = γ * (x_t / S_t) + (1 - γ) * C_(t-L)\\n\\nA construction vehicle manufacturer wants to use this model to analyze a production process\\nwhere construction vehicles are produced in batches of exactly 170, and a batch takes an\\naverage of 9 days to be completed (usually between 8 and 10). Our data includes the day each\\nvehicle’s production is completed, its sequence in the batch, the day within the batch that it\\nwas completed, and the number of hours the vehicle operated before its first breakdown.\\n\\nBased on this data, the manufacturer wants to use a triple exponential smoothing model to\\ndetermine whether any patterns exist in the number of hours before the first breakdown, based\\non a vehicle’s sequence number in its batch.\\n\\nFor each of the mathematical terms on the left, pick the appropriate number or description\\nfrom the right.\\na. x_t\\n    i. 170\\n    ii. 9\\n    iii. Sequence in batch\\n    iv. Day within batch that vehicle was produced\\n    v. Hours of operation before first breakdown\\n\\nb. L\\n    i. 170\\n    ii. 9\\n    iii. Sequence in batch\\n    iv. Day within batch that vehicle was produced\\n    v. Hours of operation before first breakdown\\n\\nc. If the manufacturer observes that the values of C are generally close to 1, except that\\nthey are significantly lower than 1 for vehicles built near the beginning of batches, what\\ncan be concluded?\\nCHOICES\\n    i. There is no effect of sequence in batch on the number of hours before the first\\n       breakdown.\\n    ii. Vehicles built early in a batch tend to break down more quickly.\\n    iii. Vehicles built early in a batch tend to break down more quickly, because\\n         workers are adjusting to the different specifications in a each new batch.\\n    iv. Vehicles built early in a batch tend to take longer to break down.\\n    v. Vehicles built early in a batch tend to take longer to break down, because\\n       workers are paying closer attention to their work early in each new batch.\\n\\nd. If the values of T tend to be slightly positive, what can be concluded?\\nCHOICES\\n    i. Vehicles built more recently tend to take longer to break down.\\n    ii. Vehicles built more recently tend to break down more quickly.\\n\\ne. Suppose the manufacturer wanted to use a regression model to answer the same\\nquestion, using the same data: two predictors (sequence in batch and day within batch)\\nand one response (hours of operation before first breakdown).\\nIf the manufacturer first used principal component analysis on the data, what would you\\nexpect?\\nCHOICES\\n    i. The first component would be much more important than the second.\\n    ii. The second component would be much more important than the first.\\n    iii. The two components would have approximately the same importance.\\n',\n",
       " '\\nQuestion 1: Model Suitability Analysis\\n\\nFor each statistical and machine learning model listed below, select the type of analysis it is best suited for.\\nThere may be more than one correct answer for each model, but you need only choose one. Assume 1 of 1 attempt for each part.\\n\\nA. Time Series Analysis (e.g., ARMA, ARIMA)\\n- Predicting future values in a time-series dataset.\\n- Classifying items based on time-dependent features.\\n- Analyzing the seasonal components of time-series data.\\n- Estimating the probability of an event occurring in the future.\\n\\nB. k-Nearest-Neighbor Classification (kNN)\\n- Using feature data to predict the amount of something two time periods in the future.\\n- Using feature data to predict the probability of something happening two time periods in the future.\\n- Using feature data to predict whether or not something will happen two time periods in the future.\\n- Using time-series data to predict the amount of something two time periods in the future.\\n- Using time-series data to predict the variance of something two time periods in the future.\\n\\nC. Exponential Smoothing\\n- Using feature data to predict the amount of something two time periods in the future.\\n- Using feature data to predict the probability of something happening two time periods in the future.\\n- Using feature data to predict whether or not something will happen two time periods in the future.\\n- Using time-series data to predict the amount of something two time periods in the future.\\n- Using time-series data to predict the variance of something two time periods in the future.\\n\\n',\n",
       " '\\nQuestion 1: Model Suitability Analysis\\n\\nFor each statistical and machine learning model listed below, select the type of analysis it is best suited for.\\nThere may be more than one correct answer for each model, but you need only choose one. Assume 1 of 1 attempt for each part.\\n\\nA. Ridge Regression\\n- Predicting a continuous response variable with feature data.\\n- Dealing with multicollinearity in regression analysis.\\n- Forecasting future values in a time-series dataset.\\n- Classifying binary outcomes.\\n\\nB. Lasso Regression\\n- Selecting important features in a large dataset.\\n- Predicting a numerical outcome based on feature data.\\n- Analyzing patterns in time-series data.\\n- Identifying categories in unstructured data.\\n\\nC. Principal Component Analysis (PCA)\\n- Reducing the dimensionality of a large dataset.\\n- Forecasting trends in a time-series dataset.\\n- Classifying items into categories based on feature data.\\n- Detecting changes in the variance of a dataset over time.\\n\\n',\n",
       " '\\nQuestion 1: Model Suitability Analysis\\n\\nFor each statistical and machine learning model listed below, select the type of analysis it is best suited for.\\nThere may be more than one correct answer for each model, but you need only choose one. Assume 1 of 1 attempt for each part.\\n\\nA. Decision Trees (e.g., CART)\\n- Predicting the category of an item based on feature data.\\n- Forecasting numerical values two time periods in the future.\\n- Identifying clusters in feature data.\\n- Analyzing the variance in time-series data.\\n\\nB. Random Forest\\n- Predicting the likelihood of an event based on feature data.\\n- Classifying items into categories based on feature data.\\n- Estimating the amount of a variable two time periods in the future using time-series data.\\n- Detecting patterns in large datasets with many variables.\\n\\nC. Naive Bayes Classifier\\n- Classifying text data into predefined categories.\\n- Predicting future trends based on historical time-series data.\\n- Estimating the probability of an event occurring in the future.\\n- Analyzing variance in feature data.\\n',\n",
       " '\\nQuestion 1\\nSelect all of the following reasons that data should not be scaled until point outliers are removed:\\n- If data is scaled first, the range of data after outliers are removed will be narrower than intended.\\n- If data is scaled first, the range of data after outliers are removed will be wider than intended.\\n- Point outliers would appear to be valid data if not removed before scaling.\\n- Valid data would appear to be outliers if data is scaled first.\\n\\nQuestion 2\\nSelect all of the following situations in which using a variable selection approach like lasso or stepwise regression would be important:\\n- It is too costly to create a model with a large number of variables.\\n- There are too few data points to avoid overfitting if all variables are included.\\n- Time-series data is being used.\\n- There are fewer data points than variables.\\n',\n",
       " \"\\nConfusion Matrix for Shoplifting Prediction Model:\\n\\n                       Predicted Not Shoplifting   Predicted Shoplifting\\nActual Not Shoplifting            1200                       300\\nActual Shoplifting                 150                       350\\n\\nThis confusion matrix represents the outcomes of a shoplifting prediction model. The model predicts whether an individual is likely to commit shoplifting ('Predicted Shoplifting')\\nor not ('Predicted Not Shoplifting'), and the results are compared against the actual occurrences ('Actual Shoplifting' and 'Actual Not Shoplifting').\\n\\nQuestions about the Shoplifting Prediction Model's Confusion Matrix:\\n\\nQuestion 1:\\n(1 point) Calculate the model's accuracy (the proportion of true results among the total number of cases examined).\\nA) (1200 + 350) / (1200 + 300 + 150 + 350)\\nB) (1200 + 150) / (1200 + 300 + 150 + 350)\\nC) (300 + 350) / (1200 + 300 + 150 + 350)\\n\\nQuestion 2:\\n(1 point) Determine the model's precision for shoplifting predictions (the proportion of correctly predicted shoplifting incidents to the total predicted as shoplifting).\\nA) 350 / (300 + 350)\\nB) 1200 / (1200 + 150)\\nC) 350 / (1200 + 350)\\n\\nQuestion 3:\\n(1 point) Calculate the model's recall for shoplifting predictions (the ability of the model to identify actual shoplifting incidents).\\nA) 350 / (150 + 350)\\nB) 300 / (1200 + 300)\\nC) 1200 / (1200 + 150)\\n\\nQuestion 4:\\n(1 point) Based on the confusion matrix, which statement is true regarding the model's predictions?\\nA) The model is more accurate in predicting non-shoplifting incidents than shoplifting incidents.\\nB) The model has the same accuracy for predicting shoplifting and non-shoplifting incidents.\\nC) The model is more accurate in predicting shoplifting incidents than non-shoplifting incidents.\\n\\n\",\n",
       " '\\n1. A group of astronomers has a set of long-exposure CCD images of various distant objects. They do not know yet which types of object each one is and would like your help using analytics to determine which ones look similar. Which is more appropriate: classification or clustering?\\n- Classification\\n- Clustering\\n\\n2. Suppose one astronomer has categorized hundreds of the images by hand, and now wants your help using analytics to automatically determine which category each new image belongs to. Which is more appropriate: classification or clustering?\\n- Classification\\n- Clustering\\n',\n",
       " '\\n5. A modeler built a support vector machine (SVM) model for a problem, and found that it correctly\\npredicted 86 percent of the training set and 76 percent of the validation set.\\na. When evaluated on the test data set, the expected correct prediction percent for the\\nSVM model is…\\n    i. …greater than 86 percent.\\n    ii. …equal to 86 percent.\\n    iii. …greater than 76 percent and less than 86 percent\\n    iv. …equal to 76 percent\\n    v. …less than 76 percent\\n\\nLater, the modeler created a second SVM model and a k‐nearest‐neighbor (kNN) model. The\\nperformance of each model on the training and validation data sets is shown in the table below.\\n\\nCorrect prediction percent (training set)\\nCorrect prediction percent (validation set)\\nSVM model 1          86 percent                       76 percent\\nSVM model 2          84 percent                       45 percent\\nkNN model            85 percent                       76 percent\\nb. Which model is most likely to be overfit?\\n\\nc. (Based on the table above, which model should you select?\\n    i. SVM model 1\\n    ii. SVM model 2\\n    iii. kNN model\\n    iv. Either SVM model 1 or kNN model, but not SVM model 2\\n    v. There’s not much difference between the three models\\n\\nd. Suppose SVM model 1 is selected as best, and its correct prediction percent on the test\\ndata set is 72 percent. An unbiased estimate of SVM model 1’s correct prediction percent on a new test\\ndata set is\\n    i. Greater than 72 percent\\n    ii. Equal to 72 percent\\n    iii. Less than 72 percent\\n']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice([MIDTERM_1_QUESTIONS,MIDTERM_2_QUESTIONS])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0aa5d8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_index = np.random.randint(0,15)\n",
    "\n",
    "final_long_form = random.choice([KNOWLEDGE_1_QUESTIONS,MIDTERM_2_QUESTIONS])\n",
    "final_short_form = random.choice([KNOWLEDGE_1_QUESTIONS,MIDTERM_2_QUESTIONS])\n",
    "\n",
    "#====================STATES===================\n",
    "mid_term_1 = {'long_form_question': MIDTERM_1_QUESTIONS[question_index], 'short_form_question': KNOWLEDGE_1_QUESTIONS[question_index], \"function\": exam_prep}\n",
    "mid_term_2 = {'long_form_question': MIDTERM_2_QUESTIONS[question_index], 'short_form_question': KNOWLEDGE_2_QUESTIONS[question_index], \"function\": exam_prep}\n",
    "final_1 = {'long_form_question': final_long_form[question_index], 'short_form_question': final_short_form[question_index], \"function\": exam_prep}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2028bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_term_1['long_form_question']\n",
    "module_review = { \"function\": 1234}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9f0207f",
   "metadata": {},
   "outputs": [],
   "source": [
    "STATES_DICTIONARY = {\n",
    "    \"mid_term_1\": mid_term_1,\n",
    "    \"mid_term_2\": mid_term_2,\n",
    "    \"final_1\": final_1,\n",
    "    \"module_review\": module_review,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7dc53907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n    An airline wants to predict airline passenger traffic for the upcoming year.\\n    For each of the specific questions (a-e) listed below, identify the question type (i-viii) it corresponds to.\\n    If a question does not match any of the listed types, leave it uncircled.\\n\\n    Question Types:\\n        i. Change detection\\n        ii. Classification\\n        iii. Clustering\\n        iv. Feature-based prediction of a value\\n        v. Feature-based prediction of a probability\\n        vi. Time-series-based prediction\\n        vii. Validation\\n        viii. Variance estimation\\n\\n    Questions:\\n        a. What is the probability that the airline will exceed 1 million passengers next year, considering current travel trends and economic factors?\\n        b. Among various forecasting models for airline passenger traffic, which one is likely to be the most accurate for the upcoming year?\\n        c. Based on the past decade's data, how many passengers are expected to travel via the airline next year?\\n        d. Analyzing the past fifteen years of data, has there been a significant change in passenger traffic during holiday seasons?\\n        e. Considering economic indicators and travel trends over the past 25 years, which years had the most similar passenger traffic patterns?\\n    \""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STATE = \"mid_term_1\"\n",
    "STATES_DICTIONARY[STATE]['long_form_question']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a46e9428",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.states import Token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eace08c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = Token('midterm_1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdd104d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6930435c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 11])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(range(15), size=2, replace=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
